{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.markdown import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSOLE = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print(text):\n",
    "    \"\"\"text: str\"\"\"\n",
    "    CONSOLE.print(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_questions(user_qs):\n",
    "    \"\"\"user_qs: UserQueries\"\"\"\n",
    "    for qs in user_qs.queries:\n",
    "        print(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_toml = toml.load('../.streamlit/secrets.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = parsed_toml['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gclient = genai.Client(api_key=parsed_toml['GEMINI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposne = gclient.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Give me a list of user personas who would be using Fiddler for AI/ML Monitoring and observability\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fiddler AI is a powerful platform for monitoring, explaining, and analyzing AI models in production. As such, the  \n",
       "user personas for Fiddler often span technical and non-technical roles, each with unique needs related to AI/ML    \n",
       "monitoring and observability.                                                                                      \n",
       "\n",
       "Here's a list of user personas who would be using Fiddler for AI/ML Monitoring and observability:                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                               <span style=\"font-weight: bold\">1. The ML Ops Engineer (The \"Guardian of Production\")</span>                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Role/Title:</span> ML Ops Engineer, Production ML Engineer, Senior DevOps Engineer (with ML focus)                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Primary Goal:</span> Ensure the continuous health, performance, and reliability of deployed AI models in production.   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Minimize downtime and quickly diagnose issues.                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Key Pain Points:</span> Unexplained model performance drops, silent failures, alert fatigue, difficulty pinpointing    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>root causes of issues (data vs. model), lack of visibility into model serving infrastructure.                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">How they use Fiddler:</span>                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Set up and monitor real-time alerts for performance degradation, data drift, and concept drift.              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Dashboard monitoring for overall model health, latency, and throughput.                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Drill down into specific model issues identified by alerts.                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Integrate Fiddler alerts with existing ops dashboards (e.g., PagerDuty, Slack).                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Track resource utilization and serving metrics related to model inference.                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Metrics they care about:</span> Model throughput, latency, error rates, data ingress/egress, alert frequency, overall  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>system uptime, specific model performance metrics (e.g., F1-score, accuracy) <span style=\"font-style: italic\">after</span> an alert.                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                   <span style=\"font-weight: bold\">2. The Data Scientist (The \"Model Whisperer\")</span>                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Role/Title:</span> Data Scientist, Senior Data Scientist, ML Scientist                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Primary Goal:</span> Understand why their models are performing as they are in the real world, identify the need for   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>retraining, and debug model behavior.                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Key Pain Points:</span> Models decaying over time (drift), unexpected model predictions, difficulty explaining model   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>decisions to stakeholders, needing to manually re-evaluate models in production, blind spots once models are    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>deployed.                                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">How they use Fiddler:</span>                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Deep dive into data drift and concept drift reports to understand why model performance is changing.         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Utilize explainability features (e.g., SHAP, LIME) to understand individual predictions or global model      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>behavior.                                                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Compare model performance against baselines and retrain triggers.                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Debug specific model prediction failures by inspecting input features and explanations.                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Generate reports for model validation and re-training justification.                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Metrics they care about:</span> Model accuracy, precision, recall, F1-score, AUC, specific fairness metrics, feature   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>distribution shifts, concept drift scores, SHAP values, LIME explanations.                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                            <span style=\"font-weight: bold\">3. The AI Product Manager (The \"Business Value Maximizer\")</span>                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Role/Title:</span> AI Product Manager, ML Product Manager, Product Owner                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Primary Goal:</span> Ensure the AI model is delivering the intended business value, understanding user impact, and     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>identifying opportunities for improvement or new features.                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Key Pain Points:</span> Lack of clear understanding of model impact on business KPIs, difficulty communicating model   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>behavior to non-technical stakeholders, unexpected user experiences driven by AI, inability to correlate model  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>performance with business outcomes.                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">How they use Fiddler:</span>                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>View high-level dashboards showcasing model performance tied to business metrics (e.g., click-through rates, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>conversion rates, fraud detection rates).                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Review explanations to understand common prediction patterns and user behavior.                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Receive summaries of model degradation or bias issues that might impact user experience or business          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>objectives.                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Use reports to justify resource allocation for model improvement or new AI initiatives.                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Metrics they care about:</span> Business KPIs influenced by the model, user engagement metrics, A/B test results (if   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>applicable), high-level model performance trends, impact of bias/fairness issues on customer segments.          \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                            <span style=\"font-weight: bold\">4. The Risk &amp; Compliance Officer (The \"Ethical AI Steward\")</span>                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Role/Title:</span> Risk Officer, Compliance Officer, Legal Counsel, Head of Responsible AI                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Primary Goal:</span> Ensure AI models are fair, transparent, explainable, and compliant with internal policies and     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>external regulations (e.g., GDPR, CCPA, upcoming AI acts). Mitigate reputational and financial risks.           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Key Pain Points:</span> Inability to prove model fairness, opaque model decision-making, difficulty auditing past model\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>predictions, lack of a clear trail for model governance, potential for discriminatory outcomes.                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">How they use Fiddler:</span>                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Monitor fairness metrics across different demographic groups or sensitive attributes.                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Access and generate audit trails for individual model predictions and changes.                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Utilize explainability features to demonstrate why a decision was made for regulatory reviews.               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Track and report on model bias over time.                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Ensure compliance with explainability and data privacy requirements.                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Metrics they care about:</span> Disparate impact ratio, equality of opportunity, demographic parity, group fairness    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>metrics, explanation fidelity, data lineage, audit logs, model versioning.                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                          <span style=\"font-weight: bold\">5. The AI/ML Team Lead / Head of AI (The \"Strategic Overseer\")</span>                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Role/Title:</span> Head of AI/ML, Director of Data Science, VP of Machine Learning                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Primary Goal:</span> Gain a holistic view of all deployed models, allocate resources effectively, assess the overall   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>health of the AI portfolio, and make strategic decisions based on model performance and ROI.                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Key Pain Points:</span> Lack of a centralized view of model performance, difficulty identifying which models need      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>immediate attention, inability to quantify the impact of MLOps efforts, resource contention across multiple     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>model teams.                                                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">How they use Fiddler:</span>                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Overview dashboards displaying the status of all active models.                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Receive high-level summaries of critical alerts and performance trends.                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Identify which teams or models require more support or investigation.                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Review consolidated reports on model ROI, risk exposure, and compliance posture.                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Use Fiddler's insights to prioritize new model development or existing model improvements.                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Metrics they care about:</span> Portfolio-level model health, number of active alerts, overall drift rates, cumulative \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>business impact, resource allocation trends, compliance status summary.                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "These personas highlight the diverse needs that Fiddler addresses, spanning the entire lifecycle of AI models in   \n",
       "production – from the technical deep dives of an ML Ops Engineer to the strategic oversight of an AI Leader.       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fiddler AI is a powerful platform for monitoring, explaining, and analyzing AI models in production. As such, the  \n",
       "user personas for Fiddler often span technical and non-technical roles, each with unique needs related to AI/ML    \n",
       "monitoring and observability.                                                                                      \n",
       "\n",
       "Here's a list of user personas who would be using Fiddler for AI/ML Monitoring and observability:                  \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                               \u001b[1m1. The ML Ops Engineer (The \"Guardian of Production\")\u001b[0m                               \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mRole/Title:\u001b[0m ML Ops Engineer, Production ML Engineer, Senior DevOps Engineer (with ML focus)                     \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mPrimary Goal:\u001b[0m Ensure the continuous health, performance, and reliability of deployed AI models in production.   \n",
       "\u001b[1;33m   \u001b[0mMinimize downtime and quickly diagnose issues.                                                                  \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mKey Pain Points:\u001b[0m Unexplained model performance drops, silent failures, alert fatigue, difficulty pinpointing    \n",
       "\u001b[1;33m   \u001b[0mroot causes of issues (data vs. model), lack of visibility into model serving infrastructure.                   \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mHow they use Fiddler:\u001b[0m                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mSet up and monitor real-time alerts for performance degradation, data drift, and concept drift.              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mDashboard monitoring for overall model health, latency, and throughput.                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mDrill down into specific model issues identified by alerts.                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mIntegrate Fiddler alerts with existing ops dashboards (e.g., PagerDuty, Slack).                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mTrack resource utilization and serving metrics related to model inference.                                   \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mMetrics they care about:\u001b[0m Model throughput, latency, error rates, data ingress/egress, alert frequency, overall  \n",
       "\u001b[1;33m   \u001b[0msystem uptime, specific model performance metrics (e.g., F1-score, accuracy) \u001b[3mafter\u001b[0m an alert.                    \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                   \u001b[1m2. The Data Scientist (The \"Model Whisperer\")\u001b[0m                                   \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mRole/Title:\u001b[0m Data Scientist, Senior Data Scientist, ML Scientist                                                 \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mPrimary Goal:\u001b[0m Understand why their models are performing as they are in the real world, identify the need for   \n",
       "\u001b[1;33m   \u001b[0mretraining, and debug model behavior.                                                                           \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mKey Pain Points:\u001b[0m Models decaying over time (drift), unexpected model predictions, difficulty explaining model   \n",
       "\u001b[1;33m   \u001b[0mdecisions to stakeholders, needing to manually re-evaluate models in production, blind spots once models are    \n",
       "\u001b[1;33m   \u001b[0mdeployed.                                                                                                       \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mHow they use Fiddler:\u001b[0m                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mDeep dive into data drift and concept drift reports to understand why model performance is changing.         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mUtilize explainability features (e.g., SHAP, LIME) to understand individual predictions or global model      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mbehavior.                                                                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mCompare model performance against baselines and retrain triggers.                                            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mDebug specific model prediction failures by inspecting input features and explanations.                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mGenerate reports for model validation and re-training justification.                                         \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mMetrics they care about:\u001b[0m Model accuracy, precision, recall, F1-score, AUC, specific fairness metrics, feature   \n",
       "\u001b[1;33m   \u001b[0mdistribution shifts, concept drift scores, SHAP values, LIME explanations.                                      \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                            \u001b[1m3. The AI Product Manager (The \"Business Value Maximizer\")\u001b[0m                             \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mRole/Title:\u001b[0m AI Product Manager, ML Product Manager, Product Owner                                               \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mPrimary Goal:\u001b[0m Ensure the AI model is delivering the intended business value, understanding user impact, and     \n",
       "\u001b[1;33m   \u001b[0midentifying opportunities for improvement or new features.                                                      \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mKey Pain Points:\u001b[0m Lack of clear understanding of model impact on business KPIs, difficulty communicating model   \n",
       "\u001b[1;33m   \u001b[0mbehavior to non-technical stakeholders, unexpected user experiences driven by AI, inability to correlate model  \n",
       "\u001b[1;33m   \u001b[0mperformance with business outcomes.                                                                             \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mHow they use Fiddler:\u001b[0m                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mView high-level dashboards showcasing model performance tied to business metrics (e.g., click-through rates, \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mconversion rates, fraud detection rates).                                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mReview explanations to understand common prediction patterns and user behavior.                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mReceive summaries of model degradation or bias issues that might impact user experience or business          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mobjectives.                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mUse reports to justify resource allocation for model improvement or new AI initiatives.                      \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mMetrics they care about:\u001b[0m Business KPIs influenced by the model, user engagement metrics, A/B test results (if   \n",
       "\u001b[1;33m   \u001b[0mapplicable), high-level model performance trends, impact of bias/fairness issues on customer segments.          \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                            \u001b[1m4. The Risk & Compliance Officer (The \"Ethical AI Steward\")\u001b[0m                            \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mRole/Title:\u001b[0m Risk Officer, Compliance Officer, Legal Counsel, Head of Responsible AI                             \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mPrimary Goal:\u001b[0m Ensure AI models are fair, transparent, explainable, and compliant with internal policies and     \n",
       "\u001b[1;33m   \u001b[0mexternal regulations (e.g., GDPR, CCPA, upcoming AI acts). Mitigate reputational and financial risks.           \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mKey Pain Points:\u001b[0m Inability to prove model fairness, opaque model decision-making, difficulty auditing past model\n",
       "\u001b[1;33m   \u001b[0mpredictions, lack of a clear trail for model governance, potential for discriminatory outcomes.                 \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mHow they use Fiddler:\u001b[0m                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mMonitor fairness metrics across different demographic groups or sensitive attributes.                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mAccess and generate audit trails for individual model predictions and changes.                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mUtilize explainability features to demonstrate why a decision was made for regulatory reviews.               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mTrack and report on model bias over time.                                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mEnsure compliance with explainability and data privacy requirements.                                         \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mMetrics they care about:\u001b[0m Disparate impact ratio, equality of opportunity, demographic parity, group fairness    \n",
       "\u001b[1;33m   \u001b[0mmetrics, explanation fidelity, data lineage, audit logs, model versioning.                                      \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                          \u001b[1m5. The AI/ML Team Lead / Head of AI (The \"Strategic Overseer\")\u001b[0m                           \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mRole/Title:\u001b[0m Head of AI/ML, Director of Data Science, VP of Machine Learning                                     \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mPrimary Goal:\u001b[0m Gain a holistic view of all deployed models, allocate resources effectively, assess the overall   \n",
       "\u001b[1;33m   \u001b[0mhealth of the AI portfolio, and make strategic decisions based on model performance and ROI.                    \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mKey Pain Points:\u001b[0m Lack of a centralized view of model performance, difficulty identifying which models need      \n",
       "\u001b[1;33m   \u001b[0mimmediate attention, inability to quantify the impact of MLOps efforts, resource contention across multiple     \n",
       "\u001b[1;33m   \u001b[0mmodel teams.                                                                                                    \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mHow they use Fiddler:\u001b[0m                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mOverview dashboards displaying the status of all active models.                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mReceive high-level summaries of critical alerts and performance trends.                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mIdentify which teams or models require more support or investigation.                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mReview consolidated reports on model ROI, risk exposure, and compliance posture.                             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mUse Fiddler's insights to prioritize new model development or existing model improvements.                   \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mMetrics they care about:\u001b[0m Portfolio-level model health, number of active alerts, overall drift rates, cumulative \n",
       "\u001b[1;33m   \u001b[0mbusiness impact, resource allocation trends, compliance status summary.                                         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "These personas highlight the diverse needs that Fiddler addresses, spanning the entire lifecycle of AI models in   \n",
       "production – from the technical deep dives of an ML Ops Engineer to the strategic oversight of an AI Leader.       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(resposne.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserQueries(BaseModel):\n",
    "    queries: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "QS_TEMPLATE = \"\"\"Give me a list of {num_questions} queries that a user would want to ask FiddleBot about their models and projects in Fiddler.\n",
    "\n",
    "Fiddler has the following capabilities:\n",
    "- Monitor performance of ML models and generative AI applications\n",
    "- Protect your LLM and GenAI applications with Guardrails\n",
    "- Analyze model behavior to identify issues and opportunities\n",
    "- Improve AI systems through actionable insights\n",
    "\n",
    "Implementing Fiddler ML/LLM monitoring requires just three steps:\n",
    "1. Onboard your ML/LLM application to Fiddler by defining its inputs, outputs, and related metadata\n",
    "2. Publish your application data to Fiddler, typically the \"digital exhaust\" from your model serving platform\n",
    "3. Monitor performance through dashboards and alerts that track the metrics most important to your use case\n",
    "\n",
    "Fiddler automatically handles the complex work of generating metrics, detecting anomalies, and providing the visualizations you need to maintain high-quality ML applications.\n",
    "\n",
    "Fiddlebot aims to be a chat based UI to the Fiddler platform, where users can ask the bot to fetch information for them. It is limited to the preprod environment on Fiddler, so please keep that in mind.\n",
    "This is also an unoptimized version and the aim of having this internal dry-run is to ascertain where and how the agent is failing, along with usage patterns. This will better inform us when it comes to optimizing performance.\n",
    "There are 3 major components working under the hood.\n",
    "- Chatbot : Chat UI\n",
    "- Plan n Solve : Certain queries require multiple steps to be resolved. The PnS module aims to first generate a plan and solve each step.\n",
    "- MCP Server : Model Context Protocol Server. A set of tools that the agent can utilise in solving for the query. Runs the Fiddler python client under the hood.\n",
    "\n",
    "Please keep in mind that the bot is still a work in progress and failure is expected. The aim of this exercise is to catch how the agent fails when it is faced with ambiguous queries, queries with incomplete parameters (ex asking for model schema without providing project) and queries which are beyond the scope of the agent.\n",
    "\n",
    "FiddleBot has access the following capabilities via tools:\n",
    "- list all projects in fiddler\n",
    "- list all models in a project\n",
    "- get model schema\n",
    "- get model specs\n",
    "- list alert rules for a model\n",
    "- list triggered alerts for a rule\n",
    "- list all custom metrics for a model\n",
    "\n",
    "{condition}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMBIGUOUS_CONDITION = \"\"\"The user is new to Fiddler and is not aware of its capabilities and what to ask for.\n",
    "Their questions are not specific and ambiguous and incomplete.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFLICTING_CONDITION = \"\"\"The user wants to test the Fiddler expert and asks questions with conflicting information and requirements\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOD_CONDITION = \"\"\"The user is familiar with Fiddler and is aware of its capabilities and what to ask for.\n",
    "The questions that the user asks are specific and clear. There is no ambiguity in the questions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gclient.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=QS_TEMPLATE.format(num_questions=40, condition=AMBIGUOUS_CONDITION),\n",
    "    config={\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_schema\": UserQueries\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = response.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's going on in Fiddler?                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's going on in Fiddler?                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tell me about my models.                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tell me about my models.                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any active projects?                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any active projects?                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me some models.                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me some models.                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What kind of data do you have for a model?                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What kind of data do you have for a model?                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any problems?                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any problems?                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">List alerts.                                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "List alerts.                                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the projects I have?                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the projects I have?                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you show me the models?                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you show me the models?                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's the schema for a model?                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's the schema for a model?                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Give me details about a model.                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Give me details about a model.                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the metrics?                                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the metrics?                                                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How are my models performing?                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How are my models performing?                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me everything you know.                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me everything you know.                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the rules for alerts?                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the rules for alerts?                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are any alerts currently triggered?                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are any alerts currently triggered?                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I need some model information.                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "I need some model information.                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the specs?                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the specs?                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me custom metrics.                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me custom metrics.                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How do I improve my models?                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How do I improve my models?                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you analyze model behavior for me?                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you analyze model behavior for me?                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What models are running in preprod?                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What models are running in preprod?                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tell me about the project I'm in.                                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tell me about the project I'm in.                                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any issues with my GenAI applications?                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any issues with my GenAI applications?                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you help me protect my LLM?                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you help me protect my LLM?                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What can you do for me?                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What can you do for me?                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Where are my models located?                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Where are my models located?                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's the status of my models?                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's the status of my models?                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I want to see the model details.                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "I want to see the model details.                                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">List all the stuff.                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "List all the stuff.                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the key metrics?                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the key metrics?                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's wrong with the performance?                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's wrong with the performance?                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How do I identify issues?                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How do I identify issues?                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you show me the outputs?                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you show me the outputs?                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What about the inputs?                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What about the inputs?                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any recommended actions?                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any recommended actions?                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What kind of guardrails are in place?                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What kind of guardrails are in place?                                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me a summary.                                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me a summary.                                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's the most important information?                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's the most important information?                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you tell me about the model called 'production_model'?                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you tell me about the model called 'production_model'?                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_questions(response.parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's going on in Fiddler?                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's going on in Fiddler?                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tell me about my models.                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tell me about my models.                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any active projects?                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any active projects?                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me some models.                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me some models.                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What kind of data do you have for a model?                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What kind of data do you have for a model?                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any problems?                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any problems?                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">List alerts.                                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "List alerts.                                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the projects I have?                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the projects I have?                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you show me the models?                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you show me the models?                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's the schema for a model?                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's the schema for a model?                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Give me details about a model.                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Give me details about a model.                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the metrics?                                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the metrics?                                                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How are my models performing?                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How are my models performing?                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me everything you know.                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me everything you know.                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the rules for alerts?                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the rules for alerts?                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are any alerts currently triggered?                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are any alerts currently triggered?                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I need some model information.                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "I need some model information.                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the specs?                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the specs?                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me custom metrics.                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me custom metrics.                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How do I improve my models?                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How do I improve my models?                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you analyze model behavior for me?                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you analyze model behavior for me?                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What models are running in preprod?                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What models are running in preprod?                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tell me about the project I'm in.                                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tell me about the project I'm in.                                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any issues with my GenAI applications?                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any issues with my GenAI applications?                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you help me protect my LLM?                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you help me protect my LLM?                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What can you do for me?                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What can you do for me?                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Where are my models located?                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Where are my models located?                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's the status of my models?                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's the status of my models?                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I want to see the model details.                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "I want to see the model details.                                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">List all the stuff.                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "List all the stuff.                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the key metrics?                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the key metrics?                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's wrong with the performance?                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's wrong with the performance?                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How do I identify issues?                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How do I identify issues?                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you show me the outputs?                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you show me the outputs?                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What about the inputs?                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What about the inputs?                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any recommended actions?                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any recommended actions?                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What kind of guardrails are in place?                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What kind of guardrails are in place?                                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me a summary.                                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me a summary.                                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's the most important information?                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's the most important information?                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you tell me about the model called 'production_model'?                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you tell me about the model called 'production_model'?                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "good_response = gclient.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=QS_TEMPLATE.format(num_questions=40, condition=GOOD_CONDITION),\n",
    "    config={\"response_mime_type\": \"application/json\", \"response_schema\": UserQueries},\n",
    ")\n",
    "good_qs = response.parsed\n",
    "print_questions(good_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's going on in Fiddler?                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's going on in Fiddler?                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tell me about my models.                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tell me about my models.                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any active projects?                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any active projects?                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me some models.                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me some models.                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What kind of data do you have for a model?                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What kind of data do you have for a model?                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any problems?                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any problems?                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">List alerts.                                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "List alerts.                                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the projects I have?                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the projects I have?                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you show me the models?                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you show me the models?                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's the schema for a model?                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's the schema for a model?                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Give me details about a model.                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Give me details about a model.                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the metrics?                                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the metrics?                                                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How are my models performing?                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How are my models performing?                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me everything you know.                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me everything you know.                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the rules for alerts?                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the rules for alerts?                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are any alerts currently triggered?                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are any alerts currently triggered?                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I need some model information.                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "I need some model information.                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the specs?                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the specs?                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me custom metrics.                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me custom metrics.                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How do I improve my models?                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How do I improve my models?                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you analyze model behavior for me?                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you analyze model behavior for me?                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What models are running in preprod?                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What models are running in preprod?                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tell me about the project I'm in.                                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tell me about the project I'm in.                                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any issues with my GenAI applications?                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any issues with my GenAI applications?                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you help me protect my LLM?                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you help me protect my LLM?                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What can you do for me?                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What can you do for me?                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Where are my models located?                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Where are my models located?                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's the status of my models?                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's the status of my models?                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I want to see the model details.                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "I want to see the model details.                                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">List all the stuff.                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "List all the stuff.                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the key metrics?                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the key metrics?                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's wrong with the performance?                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's wrong with the performance?                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How do I identify issues?                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How do I identify issues?                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you show me the outputs?                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you show me the outputs?                                                                                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What about the inputs?                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What about the inputs?                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Are there any recommended actions?                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Are there any recommended actions?                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What kind of guardrails are in place?                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What kind of guardrails are in place?                                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Show me a summary.                                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Show me a summary.                                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What's the most important information?                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What's the most important information?                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you tell me about the model called 'production_model'?                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you tell me about the model called 'production_model'?                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "good_response = gclient.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=QS_TEMPLATE.format(num_questions=40, condition=GOOD_CONDITION),\n",
    "    config={\"response_mime_type\": \"application/json\", \"response_schema\": UserQueries},\n",
    ")\n",
    "good_qs = response.parsed\n",
    "print_questions(good_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250626T07:44:24.707Z     INFO| attached stderr handler to logger: auto_attach_log_handler=True, and root logger not configured \n",
      "250626T07:44:24.709Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/server-info GET -- emit req (0 B, timeout: (5, 15)) \n",
      "250626T07:44:25.678Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/server-info GET -- resp code: 200, took 0.968 s, resp/req body size: (912 B, 0 B) \n",
      "250626T07:44:25.681Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/version-compatibility GET -- emit req (0 B, timeout: (5, 15)) \n",
      "250626T07:44:26.013Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/version-compatibility GET -- resp code: 200, took 0.330 s, resp/req body size: (2 B, 0 B) \n"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://preprod.cloud.fiddler.ai\"\n",
    "TOKEN = parsed_toml[\"FIDDLER_ACCESS_TOKEN\"]\n",
    "fdl.init(url=BASE_URL, token=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _list_all_projects() -> list[str]:\n",
    "    \"\"\"\n",
    "    List the names of all projects in the organisation\n",
    "    \"\"\"\n",
    "    print(\"Listing all projects\")\n",
    "    project_names = []\n",
    "    projects = list(fdl.Project.list())\n",
    "    try:\n",
    "        for project in projects:\n",
    "            project_names.append(str(project.name))\n",
    "        return project_names\n",
    "    except Exception as e:\n",
    "        return \"Error in obtaining projects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @server.tool()\n",
    "def _list_models_in_project(project_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    List out all model names associated with a project\n",
    "\n",
    "    Args:\n",
    "        project_name: Name of the project\n",
    "    \"\"\"\n",
    "    try:\n",
    "        project = fdl.Project.from_name(name=project_name)\n",
    "        model_names = []\n",
    "        for model in project.models:\n",
    "            model_names.append(str(model.name))\n",
    "    except Exception as e:\n",
    "        return \"Error in obtaining models\"\n",
    "    return model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_models_in_all_projects_in_organisation() -> list[str]:\n",
    "    \"\"\"\n",
    "    Tool to list all model names across all projects in the organisation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Listing all projects\")\n",
    "        model_names = []\n",
    "        project_names = _list_all_projects()\n",
    "        if not isinstance(project_names, list):\n",
    "            return \"Error in obtaining projects\"\n",
    "        print(f\"Found {len(project_names)} projects\")\n",
    "        for project_name in project_names:\n",
    "            print(f\"Listing models in project: {project_name}\")\n",
    "            model_list = _list_models_in_project(project_name)\n",
    "            if isinstance(model_list, list):\n",
    "                model_names.extend(model_list)\n",
    "            else:\n",
    "                continue\n",
    "        return model_names\n",
    "    except Exception as e:\n",
    "        print(f\"Error in obtaining models: {traceback.format_exc()}\")\n",
    "        return \"Error in obtaining models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Listing all projects                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Listing all projects                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250626T07:46:41.191Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250626T07:46:41.745Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- resp code: 200, took 0.554 s, resp/req body size: (0.014 MB, 0 B) \n",
      "250626T07:46:41.749Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250626T07:46:42.101Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- resp code: 200, took 0.352 s, resp/req body size: (0.014 MB, 0 B) \n",
      "250626T07:46:42.106Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250626T07:46:42.403Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- resp code: 200, took 0.296 s, resp/req body size: (0.014 MB, 0 B) \n",
      "250626T07:46:42.409Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250626T07:46:42.717Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- resp code: 200, took 0.307 s, resp/req body size: (0.014 MB, 0 B) \n",
      "250626T07:46:42.723Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250626T07:46:43.016Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- resp code: 200, took 0.292 s, resp/req body size: (3570 B, 0 B) \n"
     ]
    }
   ],
   "source": [
    "project_names = _list_all_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jenn_llama_classifier']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250626T07:47:00.233Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250626T07:47:00.809Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- resp code: 200, took 0.575 s, resp/req body size: (0.014 MB, 0 B) \n",
      "250626T07:47:00.814Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250626T07:47:01.108Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- resp code: 200, took 0.294 s, resp/req body size: (0.014 MB, 0 B) \n",
      "250626T07:47:01.112Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250626T07:47:01.411Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- resp code: 200, took 0.298 s, resp/req body size: (0.014 MB, 0 B) \n",
      "250626T07:47:01.416Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250626T07:47:01.717Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- resp code: 200, took 0.300 s, resp/req body size: (0.014 MB, 0 B) \n",
      "250626T07:47:01.721Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250626T07:47:02.014Z     INFO| http: https://preprod.cloud.fiddler.ai/v3/projects GET -- resp code: 200, took 0.292 s, resp/req body size: (3570 B, 0 B) \n"
     ]
    }
   ],
   "source": [
    "projects = list(fdl.Project.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wb_chart_deletion_yooo'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for project in projects:\n",
    "    names.append(str(project.name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
