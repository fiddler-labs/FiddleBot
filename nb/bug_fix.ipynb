{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ChatCompletionMessage' from 'openai' (/Users/sri/Projects/y25/FiddleBot/.venv/lib/python3.12/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatCompletionMessage, ChatCompletionMessageToolCall, Function\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ChatCompletionMessage' from 'openai' (/Users/sri/Projects/y25/FiddleBot/.venv/lib/python3.12/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import ChatCompletionMessage, ChatCompletionMessageToolCall, Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_secrets = toml.load('../.streamlit/secrets.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_client = OpenAI(api_key=parsed_secrets[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\\nYou are a helpful assistant that talks to users about Fiddler. Fiddler is the pioneer in AI Observability and Security, \\nenabling organizations to build trustworthy and responsible AI systems. Our platform helps Data Science teams, \\nMLOps engineers, and business stakeholders monitor, explain, analyze, and improve their AI deployments.\\n\\nWith Fiddler, you can:\\n- Monitor performance of ML models and generative AI applications\\n- Protect your LLM and GenAI applications with Guardrails\\n- Analyze model behavior to identify issues and opportunities\\n- Improve AI systems through actionable insights\\n\\nThe Fiddler platform is only available on the Preprod environment.\\n\\nYou will only respond to questions that are related to Fiddler. Ask the user to stick to Fiddler if they ask about other topics.\\n\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"How many models are in py_test?\"},\n",
    "    ChatCompletionMessage(\n",
    "        content=None,\n",
    "        refusal=None,\n",
    "        role=\"assistant\",\n",
    "        annotations=[],\n",
    "        audio=None,\n",
    "        function_call=None,\n",
    "        tool_calls=[\n",
    "            ChatCompletionMessageToolCall(\n",
    "                id=\"call_cHgEam6NlxyvtjZDkjp7YiYM\",\n",
    "                function=Function(\n",
    "                    arguments='{\"llm_task_prompt\":\"Determine the number of models present in the project named \\'py_test\\' on the Fiddler platform. Return only the count of models, with no additional information.\"}',\n",
    "                    name=\"FiddlerExecClient\",\n",
    "                ),\n",
    "                type=\"function\",\n",
    "            )\n",
    "        ],\n",
    "    ),\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": \"Here are the results of the executed tasks:\\n\\n- The number of models in the 'py_test' project is: 6.\",\n",
    "        \"tool_call_id\": \"call_cHgEam6NlxyvtjZDkjp7YiYM\",\n",
    "    },\n",
    "    {\"role\": \"assistant\", \"content\": \"There are 6 models in the py_test project.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Give me their names.\\nHas the user asked to query performance metrics for a given model? Think through step by step before giving your answer.\",\n",
    "    },\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
